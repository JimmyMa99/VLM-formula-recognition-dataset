import os
import sys
import cv2
import numpy as np
from PIL import Image
import tempfile
import shutil
from skimage.metrics import structural_similarity as ssim
from scipy.spatial.distance import cosine
import hashlib

# å¯¼å…¥æˆ‘ä»¬ä¹‹å‰å†™çš„LaTeXè½¬å›¾ç‰‡ç±»
from infer_core.latex2img_file import LatexToImage

class ImageSimilarity:
    def __init__(self):
        """
        åˆå§‹åŒ–å›¾åƒç›¸ä¼¼åº¦è®¡ç®—ç±»
        """
        pass
    
    def _load_image(self, image_path):
        """
        åŠ è½½å›¾åƒæ–‡ä»¶
        
        Args:
            image_path (str): å›¾åƒè·¯å¾„
            
        Returns:
            numpy.ndarray: å›¾åƒæ•°ç»„ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
        """
        try:
            if isinstance(image_path, str):
                # ä»æ–‡ä»¶è·¯å¾„åŠ è½½
                if not os.path.exists(image_path):
                    print(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    return None
                image = cv2.imread(image_path)
                if image is None:
                    # å°è¯•ç”¨PILåŠ è½½
                    pil_image = Image.open(image_path)
                    image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            else:
                # å‡è®¾ä¼ å…¥çš„å·²ç»æ˜¯numpyæ•°ç»„
                image = image_path
                
            return image
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥: {e}")
            return None
    
    def _resize_images(self, img1, img2, target_size=(256, 256)):
        """
        å°†ä¸¤å¼ å›¾ç‰‡è°ƒæ•´åˆ°ç›¸åŒå°ºå¯¸
        
        Args:
            img1, img2: è¾“å…¥å›¾åƒ
            target_size: ç›®æ ‡å°ºå¯¸
            
        Returns:
            tuple: è°ƒæ•´åçš„ä¸¤å¼ å›¾åƒ
        """
        img1_resized = cv2.resize(img1, target_size)
        img2_resized = cv2.resize(img2, target_size)
        return img1_resized, img2_resized
    
    def histogram_similarity(self, image1, image2, method='correlation'):
        """
        åŸºäºç›´æ–¹å›¾çš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            method: æ¯”è¾ƒæ–¹æ³• ('correlation', 'chi_square', 'intersection', 'bhattacharyya')
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        img1 = self._load_image(image1)
        img2 = self._load_image(image2)
        
        if img1 is None or img2 is None:
            return 0.0
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        img1, img2 = self._resize_images(img1, img2)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—ç›´æ–¹å›¾
        hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])
        hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])
        
        # å½’ä¸€åŒ–ç›´æ–¹å›¾
        cv2.normalize(hist1, hist1)
        cv2.normalize(hist2, hist2)
        
        # é€‰æ‹©æ¯”è¾ƒæ–¹æ³•
        if method == 'correlation':
            similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        elif method == 'chi_square':
            similarity = 1.0 / (1.0 + cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR))
        elif method == 'intersection':
            similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_INTERSECT)
        elif method == 'bhattacharyya':
            similarity = 1.0 - cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")
        
        return max(0.0, min(1.0, similarity))
    
    def ssim_similarity(self, image1, image2):
        """
        åŸºäºç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°(SSIM)çš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            
        Returns:
            float: SSIMåˆ†æ•° (-1åˆ°1)ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        img1 = self._load_image(image1)
        img2 = self._load_image(image2)
        
        if img1 is None or img2 is None:
            return 0.0
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        img1, img2 = self._resize_images(img1, img2)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—SSIM
        similarity_score = ssim(gray1, gray2)
        
        return similarity_score
    
    def mse_similarity(self, image1, image2):
        """
        åŸºäºå‡æ–¹è¯¯å·®(MSE)çš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        img1 = self._load_image(image1)
        img2 = self._load_image(image2)
        
        if img1 is None or img2 is None:
            return 0.0
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        img1, img2 = self._resize_images(img1, img2)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY).astype(np.float64)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY).astype(np.float64)
        
        # è®¡ç®—MSE
        mse = np.mean((gray1 - gray2) ** 2)
        
        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (MSEè¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜)
        max_mse = 255 ** 2  # æœ€å¤§å¯èƒ½çš„MSE
        similarity = 1.0 - (mse / max_mse)
        
        return max(0.0, similarity)
    
    def feature_similarity(self, image1, image2, detector='orb'):
        """
        åŸºäºç‰¹å¾ç‚¹çš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            detector: ç‰¹å¾æ£€æµ‹å™¨ç±»å‹ ('orb', 'sift')
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        img1 = self._load_image(image1)
        img2 = self._load_image(image2)
        
        if img1 is None or img2 is None:
            return 0.0
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        img1, img2 = self._resize_images(img1, img2)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
        
        # é€‰æ‹©ç‰¹å¾æ£€æµ‹å™¨
        if detector.lower() == 'orb':
            feature_detector = cv2.ORB_create()
        elif detector.lower() == 'sift':
            feature_detector = cv2.SIFT_create()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç‰¹å¾æ£€æµ‹å™¨: {detector}")
        
        # æ£€æµ‹å…³é”®ç‚¹å’Œæè¿°ç¬¦
        kp1, des1 = feature_detector.detectAndCompute(gray1, None)
        kp2, des2 = feature_detector.detectAndCompute(gray2, None)
        
        if des1 is None or des2 is None:
            return 0.0
        
        # ç‰¹å¾åŒ¹é…
        if detector.lower() == 'orb':
            matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        else:
            matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
        
        matches = matcher.match(des1, des2)
        
        if len(matches) == 0:
            return 0.0
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        good_matches = [m for m in matches if m.distance < 50]  # å¯è°ƒæ•´é˜ˆå€¼
        similarity = len(good_matches) / max(len(kp1), len(kp2))
        
        return min(1.0, similarity)
    
    def perceptual_hash_similarity(self, image1, image2, hash_size=8):
        """
        åŸºäºæ„ŸçŸ¥å“ˆå¸Œçš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            hash_size: å“ˆå¸Œå°ºå¯¸
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼
        """
        def compute_phash(image):
            # è½¬æ¢ä¸ºç°åº¦å›¾å¹¶è°ƒæ•´å°ºå¯¸
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            resized = cv2.resize(gray, (hash_size + 1, hash_size))
            
            # è®¡ç®—æ°´å¹³æ¢¯åº¦
            diff = resized[:, 1:] > resized[:, :-1]
            
            # è½¬æ¢ä¸ºå“ˆå¸Œå€¼
            return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])
        
        img1 = self._load_image(image1)
        img2 = self._load_image(image2)
        
        if img1 is None or img2 is None:
            return 0.0
        
        # è®¡ç®—æ„ŸçŸ¥å“ˆå¸Œ
        hash1 = compute_phash(img1)
        hash2 = compute_phash(img2)
        
        # è®¡ç®—æ±‰æ˜è·ç¦»
        hamming_distance = bin(hash1 ^ hash2).count('1')
        
        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
        max_distance = hash_size * hash_size
        similarity = 1.0 - (hamming_distance / max_distance)
        
        return similarity
    
    def comprehensive_similarity(self, image1, image2, weights=None):
        """
        ç»¼åˆå¤šç§æ–¹æ³•çš„ç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            image1, image2: å›¾åƒè·¯å¾„æˆ–numpyæ•°ç»„
            weights: å„æ–¹æ³•çš„æƒé‡å­—å…¸
            
        Returns:
            dict: åŒ…å«å„ç§æ–¹æ³•ç»“æœå’Œç»¼åˆåˆ†æ•°çš„å­—å…¸
        """
        if weights is None:
            weights = {
                'histogram': 0.2,
                'ssim': 0.3,
                'mse': 0.2,
                'feature': 0.2,
                'phash': 0.1
            }
        
        results = {}
        
        # è®¡ç®—å„ç§ç›¸ä¼¼åº¦
        results['histogram'] = self.histogram_similarity(image1, image2)
        results['ssim'] = (self.ssim_similarity(image1, image2) + 1) / 2  # è½¬æ¢åˆ°0-1èŒƒå›´
        results['mse'] = self.mse_similarity(image1, image2)
        results['feature'] = self.feature_similarity(image1, image2)
        results['phash'] = self.perceptual_hash_similarity(image1, image2)
        
        # è®¡ç®—åŠ æƒå¹³å‡
        comprehensive_score = sum(results[method] * weights.get(method, 0) 
                                for method in results.keys())
        
        results['comprehensive'] = comprehensive_score
        
        return results


class LatexSimilarityEvaluator:
    """
    LaTeXå…¬å¼ç›¸ä¼¼åº¦è¯„ä¼°å™¨
    ç”¨äºæ¯”è¾ƒLaTeXæ–‡æœ¬ç”Ÿæˆçš„å›¾ç‰‡ä¸æ ‡å‡†å›¾ç‰‡çš„ç›¸ä¼¼åº¦ï¼Œå¹¶æŒ‰é˜ˆå€¼è®¡ç®—æœ€ç»ˆå¾—åˆ†
    """
    
    def __init__(self, dpi=300, fontsize=12, temp_dir=None, similarity_threshold=0.6):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            dpi (int): å›¾ç‰‡DPI
            fontsize (int): å­—ä½“å¤§å°
            temp_dir (str): ä¸´æ—¶æ–‡ä»¶ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•
            similarity_threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼ç®—1åˆ†ï¼Œå¦åˆ™ç®—0åˆ†
        """
        self.latex_converter = LatexToImage(dpi=dpi, fontsize=fontsize)
        self.similarity_calculator = ImageSimilarity()
        self.temp_dir = temp_dir or tempfile.gettempdir()
        self.similarity_threshold = similarity_threshold
        
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        os.makedirs(self.temp_dir, exist_ok=True)
        
        print(f"LaTeXç›¸ä¼¼åº¦è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ä¸´æ—¶ç›®å½•: {self.temp_dir}")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
    
    def set_threshold(self, threshold):
        """
        è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
        
        Args:
            threshold (float): æ–°çš„ç›¸ä¼¼åº¦é˜ˆå€¼ (0-1)
        """
        if 0 <= threshold <= 1:
            self.similarity_threshold = threshold
            print(f"ç›¸ä¼¼åº¦é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold}")
        else:
            raise ValueError("é˜ˆå€¼å¿…é¡»åœ¨0-1ä¹‹é—´")
    
    def _read_latex_from_txt(self, txt_path):
        """
        ä»txtæ–‡ä»¶è¯»å–LaTeXå…¬å¼
        
        Args:
            txt_path (str): txtæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: LaTeXå…¬å¼å†…å®¹ï¼Œå¦‚æœè¯»å–å¤±è´¥è¿”å›None
        """
        try:
            if not os.path.exists(txt_path):
                print(f"é”™è¯¯: txtæ–‡ä»¶ä¸å­˜åœ¨ - {txt_path}")
                return None
                
            with open(txt_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                
            if not content:
                print(f"è­¦å‘Š: txtæ–‡ä»¶ä¸ºç©º - {txt_path}")
                return None
                
            return content
            
        except Exception as e:
            print(f"è¯»å–txtæ–‡ä»¶å¤±è´¥ - {txt_path}: {e}")
            return None
    
    def _generate_temp_image(self, latex_content, base_name="temp_latex"):
        """
        ç”Ÿæˆä¸´æ—¶å›¾ç‰‡
        
        Args:
            latex_content (str): LaTeXå…¬å¼å†…å®¹
            base_name (str): ä¸´æ—¶æ–‡ä»¶åŸºç¡€åç§°
            
        Returns:
            str: ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœç”Ÿæˆå¤±è´¥è¿”å›None
        """
        try:
            # ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶å
            import uuid
            temp_filename = f"{base_name}_{uuid.uuid4().hex[:8]}.png"
            temp_image_path = os.path.join(self.temp_dir, temp_filename)
            
            # ä½¿ç”¨LaTeXè½¬æ¢å™¨ç”Ÿæˆå›¾ç‰‡
            success = self.latex_converter.latex_to_image(latex_content, temp_image_path)
            
            if success and os.path.exists(temp_image_path):
                return temp_image_path
            else:
                print(f"LaTeXå›¾ç‰‡ç”Ÿæˆå¤±è´¥")
                return None
                
        except Exception as e:
            print(f"ç”Ÿæˆä¸´æ—¶å›¾ç‰‡å¤±è´¥: {e}")
            return None
    
    def evaluate_single(self, txt_path, reference_image_path, cleanup=True):
        """
        è¯„ä¼°å•ä¸ªLaTeXæ–‡æœ¬ä¸å‚è€ƒå›¾ç‰‡çš„ç›¸ä¼¼åº¦ï¼Œè¿”å›0æˆ–1çš„å¾—åˆ†
        
        Args:
            txt_path (str): åŒ…å«LaTeXå…¬å¼çš„txtæ–‡ä»¶è·¯å¾„
            reference_image_path (str): å‚è€ƒå›¾ç‰‡è·¯å¾„
            cleanup (bool): æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            dict: åŒ…å«å¾—åˆ†å’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        result = {
            'txt_path': txt_path,
            'reference_image': reference_image_path,
            'score': 0,  # æœ€ç»ˆå¾—åˆ†ï¼š0æˆ–1
            'similarity_score': 0.0,  # åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•°
            'threshold': self.similarity_threshold,
            'latex_compile_success': False,
            'similarity_above_threshold': False,
            'generated_image': None,
            'latex_content': None,
            'error': None
        }
        
        try:
            # 1. æ£€æŸ¥å‚è€ƒå›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if not os.path.exists(reference_image_path):
                result['error'] = f"å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨: {reference_image_path}"
                return result
            
            # 2. è¯»å–LaTeXå†…å®¹
            latex_content = self._read_latex_from_txt(txt_path)
            if latex_content is None:
                result['error'] = "è¯»å–LaTeXå†…å®¹å¤±è´¥"
                return result
            
            result['latex_content'] = latex_content
            
            # 3. å°è¯•ç”Ÿæˆå›¾ç‰‡ (LaTeXç¼–è¯‘)
            temp_image_path = self._generate_temp_image(latex_content)
            if temp_image_path is None:
                result['error'] = "LaTeXç¼–è¯‘å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡"
                result['latex_compile_success'] = False
                # LaTeXç¼–è¯‘å¤±è´¥ï¼Œå¾—åˆ†ä¸º0
                return result
            
            result['latex_compile_success'] = True
            result['generated_image'] = temp_image_path
            
            # 4. è®¡ç®—ç›¸ä¼¼åº¦
            similarity_results = self.similarity_calculator.comprehensive_similarity(
                temp_image_path, reference_image_path
            )
            result['similarity_score'] = similarity_results['comprehensive']
            result['detailed_scores'] = similarity_results
            
            # 5. æ ¹æ®é˜ˆå€¼åˆ¤æ–­æœ€ç»ˆå¾—åˆ†
            if result['similarity_score'] >= self.similarity_threshold:
                result['score'] = 1
                result['similarity_above_threshold'] = True
            else:
                result['score'] = 0
                result['similarity_above_threshold'] = False
            
        except Exception as e:
            result['error'] = f"è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        
        finally:
            # 6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if cleanup and 'generated_image' in result and result['generated_image']:
                try:
                    if os.path.exists(result['generated_image']):
                        os.remove(result['generated_image'])
                        if not cleanup:  # å¦‚æœä¸æ¸…ç†ï¼Œæ›´æ–°è·¯å¾„ä¿¡æ¯
                            result['generated_image'] = None
                except Exception as e:
                    print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        return result
    
    def evaluate_batch(self, txt_dir, reference_dir, output_report=None, cleanup=True):
        """
        æ‰¹é‡è¯„ä¼°LaTeXæ–‡æœ¬ä¸å‚è€ƒå›¾ç‰‡çš„ç›¸ä¼¼åº¦ï¼Œè®¡ç®—æœ€ç»ˆå¾—åˆ†ç™¾åˆ†æ¯”
        
        Args:
            txt_dir (str): åŒ…å«txtæ–‡ä»¶çš„ç›®å½•
            reference_dir (str): åŒ…å«å‚è€ƒå›¾ç‰‡çš„ç›®å½•
            output_report (str): è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
            cleanup (bool): æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            dict: åŒ…å«æœ€ç»ˆå¾—åˆ†å’Œè¯¦ç»†ç»“æœçš„å­—å…¸
        """
        # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
        txt_files = []
        for file in os.listdir(txt_dir):
            if file.endswith('.txt'):
                txt_files.append(os.path.join(txt_dir, file))
        
        if not txt_files:
            print(f"åœ¨ {txt_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°txtæ–‡ä»¶")
            return {
                'final_score': 0.0,
                'total_samples': 0,
                'passed_samples': 0,
                'results': []
            }
        
        txt_files.sort()
        
        print(f"å¼€å§‹æ‰¹é‡è¯„ä¼° {len(txt_files)} ä¸ªæ ·æœ¬...")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        
        results = []
        passed_count = 0
        total_count = len(txt_files)
        
        for i, txt_path in enumerate(txt_files, 1):
            txt_basename = os.path.basename(txt_path)
            print(f"\n[{i}/{total_count}] å¤„ç†: {txt_basename}")
            
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„å‚è€ƒå›¾ç‰‡
            txt_name = os.path.splitext(txt_basename)[0]
            
            # å°è¯•å¸¸è§çš„å›¾ç‰‡æ‰©å±•å
            reference_image = None
            for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:
                potential_ref = os.path.join(reference_dir, txt_name + ext)
                if os.path.exists(potential_ref):
                    reference_image = potential_ref
                    break
            
            if reference_image is None:
                print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å¯¹åº”çš„å‚è€ƒå›¾ç‰‡ - {txt_name}")
                result = {
                    'txt_path': txt_path,
                    'reference_image': None,
                    'score': 0,
                    'error': 'æ‰¾ä¸åˆ°å¯¹åº”çš„å‚è€ƒå›¾ç‰‡'
                }
                results.append(result)
                continue
            
            # è¯„ä¼°å•ä¸ªæ ·æœ¬
            result = self.evaluate_single(txt_path, reference_image, cleanup)
            results.append(result)
            
            # ç»Ÿè®¡å¾—åˆ†
            if result['score'] == 1:
                passed_count += 1
                status = "âœ“ é€šè¿‡"
            else:
                status = "âœ— æœªé€šè¿‡"
            
            # æ‰“å°è¯¦ç»†ä¿¡æ¯
            if result['latex_compile_success']:
                print(f"{status} - ç›¸ä¼¼åº¦: {result['similarity_score']:.4f} (é˜ˆå€¼: {self.similarity_threshold})")
            else:
                print(f"{status} - LaTeXç¼–è¯‘å¤±è´¥")
                if result['error']:
                    print(f"  é”™è¯¯: {result['error']}")
        
        # è®¡ç®—æœ€ç»ˆå¾—åˆ†ç™¾åˆ†æ¯”
        final_score_percentage = (passed_count / total_count * 100) if total_count > 0 else 0
        
        evaluation_summary = {
            'final_score': final_score_percentage,
            'total_samples': total_count,
            'passed_samples': passed_count,
            'failed_samples': total_count - passed_count,
            'similarity_threshold': self.similarity_threshold,
            'results': results
        }
        
        # æ‰“å°æ€»ç»“
        print("\n" + "="*60)
        print("è¯„ä¼°å®Œæˆ")
        print("="*60)
        print(f"æ€»æ ·æœ¬æ•°: {total_count}")
        print(f"é€šè¿‡æ ·æœ¬æ•°: {passed_count}")
        print(f"å¤±è´¥æ ·æœ¬æ•°: {total_count - passed_count}")
        print(f"æœ€ç»ˆå¾—åˆ†: {final_score_percentage:.2f}%")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        if output_report:
            self._generate_evaluation_report(evaluation_summary, output_report)
        
        return evaluation_summary
    
    def _generate_evaluation_report(self, evaluation_summary, report_path):
        """
        ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        
        Args:
            evaluation_summary (dict): è¯„ä¼°æ€»ç»“
            report_path (str): æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            results = evaluation_summary['results']
            
            # ç»Ÿè®¡LaTeXç¼–è¯‘å¤±è´¥å’Œç›¸ä¼¼åº¦ä¸è¾¾æ ‡çš„æ•°é‡
            latex_fail_count = sum(1 for r in results if not r.get('latex_compile_success', False))
            similarity_fail_count = sum(1 for r in results 
                                      if r.get('latex_compile_success', False) and not r.get('similarity_above_threshold', False))
            
            # è®¡ç®—ç›¸ä¼¼åº¦ç»Ÿè®¡ï¼ˆä»…ç¼–è¯‘æˆåŠŸçš„æ ·æœ¬ï¼‰
            compiled_results = [r for r in results if r.get('latex_compile_success', False)]
            if compiled_results:
                similarity_scores = [r['similarity_score'] for r in compiled_results]
                avg_similarity = np.mean(similarity_scores)
                median_similarity = np.median(similarity_scores)
                max_similarity = np.max(similarity_scores)
                min_similarity = np.min(similarity_scores)
            else:
                avg_similarity = median_similarity = max_similarity = min_similarity = 0.0
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = f"""LaTeXå…¬å¼ç›¸ä¼¼åº¦è¯„ä¼°æŠ¥å‘Š
{"="*60}
è¯„ä¼°æ—¶é—´: {self._get_current_time()}
ç›¸ä¼¼åº¦é˜ˆå€¼: {evaluation_summary['similarity_threshold']}

æœ€ç»ˆå¾—åˆ†ç»Ÿè®¡:
{"="*30}
æ€»æ ·æœ¬æ•°: {evaluation_summary['total_samples']}
é€šè¿‡æ ·æœ¬æ•°: {evaluation_summary['passed_samples']}
å¤±è´¥æ ·æœ¬æ•°: {evaluation_summary['failed_samples']}
æœ€ç»ˆå¾—åˆ†: {evaluation_summary['final_score']:.2f}%

å¤±è´¥åŸå› åˆ†æ:
{"="*30}
LaTeXç¼–è¯‘å¤±è´¥: {latex_fail_count} ä¸ª
ç›¸ä¼¼åº¦ä¸è¾¾æ ‡: {similarity_fail_count} ä¸ª

ç›¸ä¼¼åº¦ç»Ÿè®¡ (ä»…ç¼–è¯‘æˆåŠŸçš„æ ·æœ¬):
{"="*40}
ç¼–è¯‘æˆåŠŸæ ·æœ¬æ•°: {len(compiled_results)}
å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}
ä¸­ä½æ•°ç›¸ä¼¼åº¦: {median_similarity:.4f}
æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.4f}
æœ€ä½ç›¸ä¼¼åº¦: {min_similarity:.4f}

è¯¦ç»†ç»“æœ:
{"="*60}
"""
            
            # æŒ‰å¾—åˆ†å’Œç›¸ä¼¼åº¦æ’åº
            results.sort(key=lambda x: (x['score'], x.get('similarity_score', 0)), reverse=True)
            
            for i, result in enumerate(results, 1):
                txt_name = os.path.basename(result['txt_path'])
                score_status = "âœ“ é€šè¿‡" if result['score'] == 1 else "âœ— æœªé€šè¿‡"
                
                report_content += f"{i:3d}. {score_status} - {txt_name}\n"
                
                if result.get('latex_compile_success', False):
                    similarity = result['similarity_score']
                    threshold_status = "è¾¾æ ‡" if result.get('similarity_above_threshold', False) else "ä¸è¾¾æ ‡"
                    report_content += f"     ç›¸ä¼¼åº¦: {similarity:.4f} ({threshold_status})\n"
                    
                    if 'detailed_scores' in result:
                        report_content += f"     è¯¦ç»†åˆ†æ•°:\n"
                        for method, score in result['detailed_scores'].items():
                            if method != 'comprehensive':
                                report_content += f"       - {method}: {score:.4f}\n"
                else:
                    report_content += f"     LaTeXç¼–è¯‘å¤±è´¥\n"
                
                if result.get('error'):
                    report_content += f"     é”™è¯¯: {result['error']}\n"
                
                if result.get('latex_content'):
                    preview = result['latex_content'][:80]
                    if len(result['latex_content']) > 80:
                        preview += "..."
                    report_content += f"     å…¬å¼: {preview}\n"
                
                report_content += "\n"
            
            # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nè¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
        except Exception as e:
            print(f"ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _get_current_time(self):
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆ›å»ºè¯„ä¼°å™¨ï¼Œè®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
    evaluator = LatexSimilarityEvaluator(dpi=300, fontsize=12, similarity_threshold=0.6)
    
    # ç¤ºä¾‹ç”¨æ³•1: å•ä¸ªæ–‡ä»¶è¯„ä¼°
    print("="*60)
    print("å•ä¸ªæ–‡ä»¶è¯„ä¼°ç¤ºä¾‹")
    print("="*60)
    
    txt_path = "./samples/sample001.txt"
    ref_image_path = "./reference/sample001.png"
    
    if os.path.exists(txt_path) and os.path.exists(ref_image_path):
        result = evaluator.evaluate_single(txt_path, ref_image_path)
        
        print(f"è¯„ä¼°ç»“æœ:")
        print(f"æœ€ç»ˆå¾—åˆ†: {result['score']} (0=æœªé€šè¿‡, 1=é€šè¿‡)")
        print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {result['similarity_score']:.4f}")
        print(f"é˜ˆå€¼: {result['threshold']}")
        print(f"LaTeXç¼–è¯‘æˆåŠŸ: {result['latex_compile_success']}")
        print(f"ç›¸ä¼¼åº¦è¾¾æ ‡: {result['similarity_above_threshold']}")
        if result['error']:
            print(f"é”™è¯¯: {result['error']}")
    else:
        print("ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å•ä¸ªæ–‡ä»¶æµ‹è¯•")
    
    # ç¤ºä¾‹ç”¨æ³•2: æ‰¹é‡è¯„ä¼°
    print("\n" + "="*60)
    print("æ‰¹é‡è¯„ä¼°ç¤ºä¾‹")
    print("="*60)
    
    txt_dir = "./samples_test2"
    ref_dir = "./output"
    report_path = "./evaluation_report.txt"
    
    if os.path.exists(txt_dir):
        # å¯ä»¥åŠ¨æ€è°ƒæ•´é˜ˆå€¼
        evaluator.set_threshold(0.99)  # è®¾ç½®æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        
        summary = evaluator.evaluate_batch(
            txt_dir=txt_dir,
            reference_dir=ref_dir,
            output_report=report_path,
            cleanup=True
        )
        
        print(f"\nğŸ¯ æœ€ç»ˆå¾—åˆ†: {summary['final_score']:.2f}%")
        print(f"ğŸ“Š é€šè¿‡ç‡: {summary['passed_samples']}/{summary['total_samples']}")
    else:
        print("ç¤ºä¾‹ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ‰¹é‡æµ‹è¯•")
        print("\nä½¿ç”¨è¯´æ˜:")
        print("1. å‡†å¤‡txtæ–‡ä»¶ç›®å½•ï¼ŒåŒ…å«LaTeXå…¬å¼")
        print("2. å‡†å¤‡å‚è€ƒå›¾ç‰‡ç›®å½•ï¼Œå›¾ç‰‡åç§°ä¸txtæ–‡ä»¶å¯¹åº”")
        print("3. è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼: evaluator.set_threshold(0.6)")
        print("4. è°ƒç”¨ evaluator.evaluate_batch() è·å¾—æœ€ç»ˆå¾—åˆ†ç™¾åˆ†æ¯”")