import os
import sys
import hashlib
from pathlib import Path

class HashTestInterface:
    """
    å“ˆå¸Œå€¼æµ‹è¯•æ¥å£
    ä¸“é—¨ç”¨äºæ¯”è¾ƒLaTeXç”Ÿæˆçš„å›¾ç‰‡ä¸å‚è€ƒå›¾ç‰‡çš„å“ˆå¸Œå€¼
    """
    
    def __init__(self):
        self.supported_algorithms = ['md5', 'sha1', 'sha256']
    
    def calculate_file_hash(self, file_path, algorithm='md5'):
        """
        è®¡ç®—å•ä¸ªæ–‡ä»¶çš„å“ˆå¸Œå€¼
        
        Args:
            file_path (str): æ–‡ä»¶è·¯å¾„
            algorithm (str): å“ˆå¸Œç®—æ³•
            
        Returns:
            str: å“ˆå¸Œå€¼ï¼Œå¤±è´¥è¿”å›None
        """
        if not os.path.exists(file_path):
            return None
        
        try:
            if algorithm == 'md5':
                hasher = hashlib.md5()
            elif algorithm == 'sha1':
                hasher = hashlib.sha1()
            elif algorithm == 'sha256':
                hasher = hashlib.sha256()
            else:
                print(f"ä¸æ”¯æŒçš„ç®—æ³•: {algorithm}")
                return None
            
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hasher.update(chunk)
            
            return hasher.hexdigest()
            
        except Exception as e:
            print(f"è®¡ç®—å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return None
    
    def find_matching_files(self, txt_dir, ref_dir):
        """
        æ‰¾åˆ°txtæ–‡ä»¶å¯¹åº”çš„å‚è€ƒå›¾ç‰‡æ–‡ä»¶
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•
            
        Returns:
            list: åŒ¹é…çš„æ–‡ä»¶å¯¹åˆ—è¡¨
        """
        matches = []
        
        if not os.path.exists(txt_dir):
            print(f"txtç›®å½•ä¸å­˜åœ¨: {txt_dir}")
            return matches
        
        if not os.path.exists(ref_dir):
            print(f"å‚è€ƒç›®å½•ä¸å­˜åœ¨: {ref_dir}")
            return matches
        
        # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
        txt_files = []
        for file in os.listdir(txt_dir):
            if file.endswith('.txt'):
                txt_files.append(file)
        
        txt_files.sort()
        
        # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
        for txt_file in txt_files:
            txt_path = os.path.join(txt_dir, txt_file)
            base_name = os.path.splitext(txt_file)[0]  # å»æ‰.txtæ‰©å±•å
            
            # å°è¯•å¸¸è§çš„å›¾ç‰‡æ‰©å±•å
            ref_image = None
            for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:
                potential_ref = os.path.join(ref_dir, base_name + ext)
                if os.path.exists(potential_ref):
                    ref_image = potential_ref
                    break
            
            matches.append({
                'txt_file': txt_path,
                'ref_image': ref_image,
                'base_name': base_name
            })
        
        return matches
    
    def generate_images_from_txt(self, txt_dir, temp_output_dir):
        """
        ä»txtæ–‡ä»¶ç”Ÿæˆä¸´æ—¶å›¾ç‰‡ç”¨äºå“ˆå¸Œæ¯”è¾ƒ
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            temp_output_dir (str): ä¸´æ—¶è¾“å‡ºç›®å½•
            
        Returns:
            list: ç”Ÿæˆç»“æœåˆ—è¡¨
        """
        # å¯¼å…¥LaTeXè½¬æ¢å™¨
        try:
            from infer_core.latex2img_file import LatexToImage
        except ImportError:
            print("é”™è¯¯: æ— æ³•å¯¼å…¥ latex2img_file æ¨¡å—")
            print("è¯·ç¡®ä¿ latex2img_file.py åœ¨å½“å‰ç›®å½•æˆ–Pythonè·¯å¾„ä¸­")
            return []
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        os.makedirs(temp_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–LaTeXè½¬æ¢å™¨
        converter = LatexToImage(dpi=300, fontsize=12)
        
        results = []
        
        # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
        txt_files = []
        for file in os.listdir(txt_dir):
            if file.endswith('.txt'):
                txt_files.append(file)
        
        txt_files.sort()
        
        print(f"å¼€å§‹ä» {len(txt_files)} ä¸ªtxtæ–‡ä»¶ç”Ÿæˆå›¾ç‰‡...")
        
        for i, txt_file in enumerate(txt_files, 1):
            txt_path = os.path.join(txt_dir, txt_file)
            base_name = os.path.splitext(txt_file)[0]
            output_path = os.path.join(temp_output_dir, f"{base_name}.png")
            
            print(f"[{i}/{len(txt_files)}] å¤„ç†: {txt_file}")
            
            try:
                # è¯»å–LaTeXå†…å®¹
                with open(txt_path, 'r', encoding='utf-8') as f:
                    latex_content = f.read().strip()
                
                if not latex_content:
                    print(f"  è­¦å‘Š: txtæ–‡ä»¶ä¸ºç©º")
                    results.append({
                        'txt_file': txt_path,
                        'generated_image': None,
                        'success': False,
                        'error': 'txtæ–‡ä»¶ä¸ºç©º'
                    })
                    continue
                
                # ç”Ÿæˆå›¾ç‰‡
                success = converter.latex_to_image(latex_content, output_path)
                
                if success and os.path.exists(output_path):
                    print(f"  âœ“ ç”ŸæˆæˆåŠŸ: {base_name}.png")
                    results.append({
                        'txt_file': txt_path,
                        'generated_image': output_path,
                        'success': True,
                        'latex_content': latex_content
                    })
                else:
                    print(f"  âœ— ç”Ÿæˆå¤±è´¥")
                    results.append({
                        'txt_file': txt_path,
                        'generated_image': None,
                        'success': False,
                        'error': 'LaTeXç¼–è¯‘å¤±è´¥'
                    })
                    
            except Exception as e:
                print(f"  âœ— å¤„ç†å¤±è´¥: {e}")
                results.append({
                    'txt_file': txt_path,
                    'generated_image': None,
                    'success': False,
                    'error': str(e)
                })
        
        return results
    
    def compare_hash_values(self, txt_dir, ref_dir, report_path, algorithm='md5'):
        """
        æ¯”è¾ƒtxtç”Ÿæˆçš„å›¾ç‰‡ä¸å‚è€ƒå›¾ç‰‡çš„å“ˆå¸Œå€¼
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•  
            report_path (str): æŠ¥å‘Šè¾“å‡ºè·¯å¾„
            algorithm (str): å“ˆå¸Œç®—æ³•
            
        Returns:
            dict: æ¯”è¾ƒç»“æœç»Ÿè®¡
        """
        print("=" * 60)
        print("å“ˆå¸Œå€¼æ¯”è¾ƒæµ‹è¯•")
        print("=" * 60)
        print(f"txtç›®å½•: {txt_dir}")
        print(f"å‚è€ƒç›®å½•: {ref_dir}")
        print(f"å“ˆå¸Œç®—æ³•: {algorithm}")
        print(f"æŠ¥å‘Šè·¯å¾„: {report_path}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”Ÿæˆå›¾ç‰‡
        temp_dir = "./temp_generated_images"
        
        try:
            # 1. ä»txtæ–‡ä»¶ç”Ÿæˆå›¾ç‰‡
            print(f"\næ­¥éª¤1: ä»txtæ–‡ä»¶ç”Ÿæˆå›¾ç‰‡åˆ°ä¸´æ—¶ç›®å½• {temp_dir}")
            generation_results = self.generate_images_from_txt(txt_dir, temp_dir)
            
            # 2. æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹
            print(f"\næ­¥éª¤2: æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å¯¹")
            matches = self.find_matching_files(txt_dir, ref_dir)
            
            # 3. è¿›è¡Œå“ˆå¸Œæ¯”è¾ƒ
            print(f"\næ­¥éª¤3: è¿›è¡Œå“ˆå¸Œå€¼æ¯”è¾ƒ")
            comparison_results = []
            identical_count = 0
            different_count = 0
            missing_count = 0
            generation_failed_count = 0
            
            for match in matches:
                base_name = match['base_name']
                txt_file = match['txt_file']
                ref_image = match['ref_image']
                generated_image = os.path.join(temp_dir, f"{base_name}.png")
                
                result = {
                    'base_name': base_name,
                    'txt_file': txt_file,
                    'ref_image': ref_image,
                    'generated_image': generated_image,
                    'ref_exists': ref_image is not None and os.path.exists(ref_image),
                    'generated_exists': os.path.exists(generated_image),
                    'ref_hash': None,
                    'generated_hash': None,
                    'identical': False,
                    'status': None
                }
                
                print(f"\nå¤„ç†: {base_name}")
                
                # æ£€æŸ¥å‚è€ƒå›¾ç‰‡æ˜¯å¦å­˜åœ¨
                if not result['ref_exists']:
                    print(f"  âœ— å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨")
                    result['status'] = 'missing_reference'
                    missing_count += 1
                elif not result['generated_exists']:
                    print(f"  âœ— ç”Ÿæˆå›¾ç‰‡å¤±è´¥")
                    result['status'] = 'generation_failed'
                    generation_failed_count += 1
                else:
                    # è®¡ç®—å“ˆå¸Œå€¼
                    ref_hash = self.calculate_file_hash(ref_image, algorithm)
                    gen_hash = self.calculate_file_hash(generated_image, algorithm)
                    
                    result['ref_hash'] = ref_hash
                    result['generated_hash'] = gen_hash
                    
                    if ref_hash and gen_hash:
                        result['identical'] = (ref_hash == gen_hash)
                        
                        if result['identical']:
                            print(f"  âœ“ å“ˆå¸Œå€¼ç›¸åŒ: {ref_hash}")
                            result['status'] = 'identical'
                            identical_count += 1
                        else:
                            print(f"  âœ— å“ˆå¸Œå€¼ä¸åŒ:")
                            print(f"    å‚è€ƒ: {ref_hash}")
                            print(f"    ç”Ÿæˆ: {gen_hash}")
                            result['status'] = 'different'
                            different_count += 1
                    else:
                        print(f"  âœ— æ— æ³•è®¡ç®—å“ˆå¸Œå€¼")
                        result['status'] = 'hash_failed'
                        different_count += 1
                
                comparison_results.append(result)
            
            # 4. ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
            total_count = len(comparison_results)
            summary = {
                'total_samples': total_count,
                'identical_count': identical_count,
                'different_count': different_count,
                'missing_reference_count': missing_count,
                'generation_failed_count': generation_failed_count,
                'identical_rate': (identical_count / total_count * 100) if total_count > 0 else 0,
                'comparison_results': comparison_results,
                'algorithm': algorithm
            }
            
            # 5. ç”ŸæˆæŠ¥å‘Š
            self._generate_hash_report(summary, report_path)
            
            # 6. æ‰“å°æ€»ç»“
            print(f"\n" + "=" * 60)
            print("å“ˆå¸Œæ¯”è¾ƒå®Œæˆ")
            print("=" * 60)
            print(f"æ€»æ ·æœ¬æ•°: {total_count}")
            print(f"å“ˆå¸Œç›¸åŒ: {identical_count}")
            print(f"å“ˆå¸Œä¸åŒ: {different_count}")
            print(f"ç¼ºå°‘å‚è€ƒ: {missing_count}")
            print(f"ç”Ÿæˆå¤±è´¥: {generation_failed_count}")
            print(f"ç›¸åŒç‡: {summary['identical_rate']:.2f}%")
            
            return summary
            
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                import shutil
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                    print(f"\nä¸´æ—¶ç›®å½•å·²æ¸…ç†: {temp_dir}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    
    def _generate_hash_report(self, summary, report_path):
        """
        ç”Ÿæˆå“ˆå¸Œæ¯”è¾ƒæŠ¥å‘Š
        
        Args:
            summary (dict): æ¯”è¾ƒç»“æœç»Ÿè®¡
            report_path (str): æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            
            report_content = f"""å“ˆå¸Œå€¼æ¯”è¾ƒæµ‹è¯•æŠ¥å‘Š
{"=" * 60}
æµ‹è¯•æ—¶é—´: {self._get_current_time()}
å“ˆå¸Œç®—æ³•: {summary['algorithm']}

æ€»ä½“ç»Ÿè®¡:
{"=" * 30}
æ€»æ ·æœ¬æ•°: {summary['total_samples']}
å“ˆå¸Œç›¸åŒ: {summary['identical_count']}
å“ˆå¸Œä¸åŒ: {summary['different_count']}
ç¼ºå°‘å‚è€ƒå›¾ç‰‡: {summary['missing_reference_count']}
ç”Ÿæˆå¤±è´¥: {summary['generation_failed_count']}
ç›¸åŒç‡: {summary['identical_rate']:.2f}%

è¯¦ç»†ç»“æœ:
{"=" * 60}
"""
            
            # æŒ‰çŠ¶æ€åˆ†ç»„æ˜¾ç¤º
            status_groups = {
                'identical': [],
                'different': [],
                'missing_reference': [],
                'generation_failed': [],
                'hash_failed': []
            }
            
            for result in summary['comparison_results']:
                status = result.get('status', 'unknown')
                if status in status_groups:
                    status_groups[status].append(result)
            
            # æ˜¾ç¤ºç›¸åŒçš„æ–‡ä»¶
            if status_groups['identical']:
                report_content += f"\nâœ“ å“ˆå¸Œå€¼ç›¸åŒçš„æ–‡ä»¶ ({len(status_groups['identical'])} ä¸ª):\n"
                for result in status_groups['identical']:
                    report_content += f"  {result['base_name']}: {result['ref_hash']}\n"
            
            # æ˜¾ç¤ºä¸åŒçš„æ–‡ä»¶
            if status_groups['different']:
                report_content += f"\nâœ— å“ˆå¸Œå€¼ä¸åŒçš„æ–‡ä»¶ ({len(status_groups['different'])} ä¸ª):\n"
                for result in status_groups['different']:
                    report_content += f"  {result['base_name']}:\n"
                    report_content += f"    å‚è€ƒ: {result['ref_hash']}\n"
                    report_content += f"    ç”Ÿæˆ: {result['generated_hash']}\n"
            
            # æ˜¾ç¤ºç¼ºå°‘å‚è€ƒçš„æ–‡ä»¶
            if status_groups['missing_reference']:
                report_content += f"\nâš  ç¼ºå°‘å‚è€ƒå›¾ç‰‡çš„æ–‡ä»¶ ({len(status_groups['missing_reference'])} ä¸ª):\n"
                for result in status_groups['missing_reference']:
                    report_content += f"  {result['base_name']}\n"
            
            # æ˜¾ç¤ºç”Ÿæˆå¤±è´¥çš„æ–‡ä»¶
            if status_groups['generation_failed']:
                report_content += f"\nâŒ ç”Ÿæˆå¤±è´¥çš„æ–‡ä»¶ ({len(status_groups['generation_failed'])} ä¸ª):\n"
                for result in status_groups['generation_failed']:
                    report_content += f"  {result['base_name']}\n"
            
            # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nå“ˆå¸Œæ¯”è¾ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
        except Exception as e:
            print(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _get_current_time(self):
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    txt_dir = "./samples_test2"
    ref_dir = "./output"  
    report_path = "./hash_comparison_report.txt"
    
    print("LaTeXå›¾ç‰‡å“ˆå¸Œå€¼æ¯”è¾ƒæµ‹è¯•")
    print("=" * 60)
    print(f"é…ç½®ä¿¡æ¯:")
    print(f"  txtæ–‡ä»¶ç›®å½•: {txt_dir}")
    print(f"  å‚è€ƒå›¾ç‰‡ç›®å½•: {ref_dir}")
    print(f"  æŠ¥å‘Šè¾“å‡ºè·¯å¾„: {report_path}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(txt_dir):
        print(f"\né”™è¯¯: txtç›®å½•ä¸å­˜åœ¨ - {txt_dir}")
        return
    
    if not os.path.exists(ref_dir):
        print(f"\né”™è¯¯: å‚è€ƒç›®å½•ä¸å­˜åœ¨ - {ref_dir}")
        return
    
    # åˆ›å»ºæµ‹è¯•æ¥å£
    hash_tester = HashTestInterface()
    
    # é€‰æ‹©å“ˆå¸Œç®—æ³•
    algorithm = 'md5'  # å¯ä»¥æ”¹ä¸º 'sha1' æˆ– 'sha256'
    
    # æ‰§è¡Œå“ˆå¸Œæ¯”è¾ƒæµ‹è¯•
    try:
        summary = hash_tester.compare_hash_values(txt_dir, ref_dir, report_path, algorithm)
        
        # æ˜¾ç¤ºç»“è®º
        print(f"\n" + "=" * 60)
        print("æµ‹è¯•ç»“è®º")
        print("=" * 60)
        
        if summary['identical_rate'] == 100:
            print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶çš„å“ˆå¸Œå€¼éƒ½ç›¸åŒï¼")
            print("   è¿™è¯´æ˜ç”Ÿæˆçš„å›¾ç‰‡ä¸å‚è€ƒå›¾ç‰‡å®Œå…¨ä¸€è‡´ã€‚")
        elif summary['identical_rate'] > 90:
            print("âœ… å¤§éƒ¨åˆ†æ–‡ä»¶çš„å“ˆå¸Œå€¼ç›¸åŒã€‚")
            print(f"   ç›¸åŒç‡: {summary['identical_rate']:.2f}%")
        elif summary['identical_rate'] > 50:
            print("âš ï¸  éƒ¨åˆ†æ–‡ä»¶çš„å“ˆå¸Œå€¼ç›¸åŒã€‚")
            print(f"   ç›¸åŒç‡: {summary['identical_rate']:.2f}%")
        else:
            print("âŒ å¤§éƒ¨åˆ†æ–‡ä»¶çš„å“ˆå¸Œå€¼ä¸åŒã€‚")
            print(f"   ç›¸åŒç‡: {summary['identical_rate']:.2f}%")
        
        if summary['different_count'] > 0:
            print(f"\nğŸ’¡ å‘ç° {summary['different_count']} ä¸ªæ–‡ä»¶å“ˆå¸Œå€¼ä¸åŒ")
            print("   å¯èƒ½åŸå› :")
            print("   1. LaTeXç¼–è¯‘è¿‡ç¨‹ä¸­çš„å¾®å°å·®å¼‚")
            print("   2. å›¾ç‰‡ç”Ÿæˆæ—¶é—´æˆ³æˆ–å…ƒæ•°æ®ä¸åŒ")
            print("   3. æµ®ç‚¹æ•°ç²¾åº¦å¯¼è‡´çš„åƒç´ å¾®å°å·®å¼‚")
        
    except Exception as e:
        print(f"\næ‰§è¡Œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()