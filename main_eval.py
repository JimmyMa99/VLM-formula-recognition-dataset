import os
import sys
import shutil
from pathlib import Path

# å¯¼å…¥è¯„ä¼°æ¨¡å—
sys.path.append('./eval_core')
sys.path.append('./eval_core')
from eval_core.cal_score_hash import HashTestInterface
from eval_core.cal_score import LatexSimilarityEvaluator

class ComprehensiveEvaluator:
    """
    ç»¼åˆè¯„ä¼°å™¨
    ç»“åˆå“ˆå¸Œå€¼æ¯”è¾ƒå’Œå›¾åƒç›¸ä¼¼åº¦è®¡ç®—ï¼Œé€šè¿‡åŠ æƒæ–¹å¼å¾—å‡ºæœ€ç»ˆå¾—åˆ†
    """
    
    def __init__(self, hash_weight=0.5, similarity_weight=0.5, similarity_threshold=0.6):
        """
        åˆå§‹åŒ–ç»¼åˆè¯„ä¼°å™¨
        
        Args:
            hash_weight (float): å“ˆå¸Œæ¯”è¾ƒçš„æƒé‡
            similarity_weight (float): ç›¸ä¼¼åº¦è®¡ç®—çš„æƒé‡
            similarity_threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.hash_weight = hash_weight
        self.similarity_weight = similarity_weight
        self.similarity_threshold = similarity_threshold
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = hash_weight + similarity_weight
        if abs(total_weight - 1.0) > 1e-6:
            print(f"è­¦å‘Š: æƒé‡å’Œä¸ä¸º1 ({total_weight})ï¼Œå°†è‡ªåŠ¨å½’ä¸€åŒ–")
            self.hash_weight = hash_weight / total_weight
            self.similarity_weight = similarity_weight / total_weight
        
        print(f"ç»¼åˆè¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"å“ˆå¸Œæ¯”è¾ƒæƒé‡: {self.hash_weight}")
        print(f"ç›¸ä¼¼åº¦è®¡ç®—æƒé‡: {self.similarity_weight}")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        
        # åˆå§‹åŒ–å­è¯„ä¼°å™¨
        self.hash_tester = HashTestInterface()
        self.similarity_evaluator = LatexSimilarityEvaluator(
            dpi=300, 
            fontsize=12, 
            similarity_threshold=similarity_threshold
        )
    
    def evaluate_comprehensive(self, txt_dir, ref_dir, output_report=None, keep_temp_images=False):
        """
        ç»¼åˆè¯„ä¼°ï¼šç»“åˆå“ˆå¸Œæ¯”è¾ƒå’Œç›¸ä¼¼åº¦è®¡ç®—
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•
            output_report (str): è¾“å‡ºæŠ¥å‘Šè·¯å¾„
            keep_temp_images (bool): æ˜¯å¦ä¿ç•™ä¸´æ—¶ç”Ÿæˆçš„å›¾ç‰‡
            
        Returns:
            dict: ç»¼åˆè¯„ä¼°ç»“æœ
        """
        print("=" * 80)
        print("ç»¼åˆè¯„ä¼°å¼€å§‹")
        print("=" * 80)
        print(f"txtç›®å½•: {txt_dir}")
        print(f"å‚è€ƒç›®å½•: {ref_dir}")
        print(f"å“ˆå¸Œæƒé‡: {self.hash_weight}")
        print(f"ç›¸ä¼¼åº¦æƒé‡: {self.similarity_weight}")
        
        # æ£€æŸ¥ç›®å½•
        if not os.path.exists(txt_dir):
            raise FileNotFoundError(f"txtç›®å½•ä¸å­˜åœ¨: {txt_dir}")
        if not os.path.exists(ref_dir):
            raise FileNotFoundError(f"å‚è€ƒç›®å½•ä¸å­˜åœ¨: {ref_dir}")
        
        # é¦–å…ˆç»Ÿè®¡æ€»çš„æµ‹è¯•é›†æ•°é‡
        total_test_samples = self._count_total_samples(txt_dir)
        print(f"æ€»æµ‹è¯•æ ·æœ¬æ•°: {total_test_samples}")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡
        temp_generated_dir = "./temp_comprehensive_eval"
        os.makedirs(temp_generated_dir, exist_ok=True)
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå›¾ç‰‡å¹¶è¿›è¡Œå“ˆå¸Œæ¯”è¾ƒ
            print(f"\n{'='*60}")
            print("ç¬¬ä¸€æ­¥ï¼šå“ˆå¸Œå€¼æ¯”è¾ƒè¯„ä¼°")
            print(f"{'='*60}")
            
            hash_results = self._evaluate_hash_comparison(txt_dir, ref_dir, temp_generated_dir, total_test_samples)
            
            # ç¬¬äºŒæ­¥ï¼šè¿›è¡Œç›¸ä¼¼åº¦è®¡ç®— (åŸºäºæ€»æ ·æœ¬æ•°ï¼Œä¸æ˜¯æˆåŠŸç”Ÿæˆçš„æ•°é‡)
            print(f"\n{'='*60}")
            print("ç¬¬äºŒæ­¥ï¼šå›¾åƒç›¸ä¼¼åº¦è¯„ä¼°")
            print(f"{'='*60}")
            
            similarity_results = self._evaluate_similarity_correct(txt_dir, ref_dir, temp_generated_dir, total_test_samples)
            
            # ç¬¬ä¸‰æ­¥ï¼šç»¼åˆè®¡ç®—æœ€ç»ˆå¾—åˆ†
            print(f"\n{'='*60}")
            print("ç¬¬ä¸‰æ­¥ï¼šç»¼åˆå¾—åˆ†è®¡ç®—")
            print(f"{'='*60}")
            
            comprehensive_results = self._calculate_comprehensive_score(hash_results, similarity_results)
            
            # ç¬¬å››æ­¥ï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Š
            if output_report:
                self._generate_comprehensive_report(comprehensive_results, output_report)
            
            # æ‰“å°æœ€ç»ˆç»“æœ
            self._print_final_results(comprehensive_results)
            
            return comprehensive_results
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not keep_temp_images:
                try:
                    if os.path.exists(temp_generated_dir):
                        shutil.rmtree(temp_generated_dir)
                        print(f"\nä¸´æ—¶ç›®å½•å·²æ¸…ç†: {temp_generated_dir}")
                except Exception as e:
                    print(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
            else:
                print(f"\nç”Ÿæˆçš„å›¾ç‰‡å·²ä¿å­˜åˆ°: {temp_generated_dir}")
    
    def _count_total_samples(self, txt_dir):
        """
        ç»Ÿè®¡æ€»çš„æµ‹è¯•æ ·æœ¬æ•°é‡
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            
        Returns:
            int: æ€»æ ·æœ¬æ•°
        """
        txt_files = [f for f in os.listdir(txt_dir) if f.endswith('.txt')]
        return len(txt_files)
    
    def _evaluate_hash_comparison(self, txt_dir, ref_dir, temp_generated_dir, total_samples):
        """
        æ‰§è¡Œå“ˆå¸Œå€¼æ¯”è¾ƒè¯„ä¼°
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•
            temp_generated_dir (str): ä¸´æ—¶ç”Ÿæˆå›¾ç‰‡ç›®å½•
            total_samples (int): æ€»æ ·æœ¬æ•°
            
        Returns:
            dict: å“ˆå¸Œæ¯”è¾ƒç»“æœ
        """
        # ç”Ÿæˆå›¾ç‰‡
        generation_results = self.hash_tester.generate_images_from_txt(txt_dir, temp_generated_dir)
        
        # è·å–æ‰€æœ‰txtæ–‡ä»¶åˆ—è¡¨
        txt_files = [f for f in os.listdir(txt_dir) if f.endswith('.txt')]
        txt_files.sort()
        
        # è¿›è¡Œå“ˆå¸Œæ¯”è¾ƒï¼Œç¡®ä¿è¦†ç›–æ‰€æœ‰æµ‹è¯•æ ·æœ¬
        hash_comparison_results = []
        hash_identical_count = 0
        
        for txt_file in txt_files:
            base_name = os.path.splitext(txt_file)[0]
            
            # æŸ¥æ‰¾å¯¹åº”çš„å‚è€ƒå›¾ç‰‡
            ref_image = None
            for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:
                potential_ref = os.path.join(ref_dir, base_name + ext)
                if os.path.exists(potential_ref):
                    ref_image = potential_ref
                    break
            
            generated_image = os.path.join(temp_generated_dir, f"{base_name}.png")
            
            result = {
                'base_name': base_name,
                'txt_file': os.path.join(txt_dir, txt_file),
                'ref_image': ref_image,
                'generated_image': generated_image,
                'ref_exists': ref_image is not None,
                'generated_exists': os.path.exists(generated_image),
                'hash_identical': False,
                'hash_score': 0,  # 0 æˆ– 1
                'error': None
            }
            
            if not result['ref_exists']:
                result['error'] = 'å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨'
                print(f"  âœ— {base_name}: å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨")
            elif not result['generated_exists']:
                result['error'] = 'LaTeXç¼–è¯‘å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡'
                print(f"  âœ— {base_name}: LaTeXç¼–è¯‘å¤±è´¥")
            else:
                # è®¡ç®—å“ˆå¸Œå€¼æ¯”è¾ƒ
                ref_hash = self.hash_tester.calculate_file_hash(ref_image)
                gen_hash = self.hash_tester.calculate_file_hash(generated_image)
                
                if ref_hash and gen_hash and ref_hash == gen_hash:
                    result['hash_identical'] = True
                    result['hash_score'] = 1
                    hash_identical_count += 1
                    print(f"  âœ“ {base_name}: å“ˆå¸Œå€¼ç›¸åŒ")
                else:
                    print(f"  âœ— {base_name}: å“ˆå¸Œå€¼ä¸åŒ")
            
            hash_comparison_results.append(result)
        
        # ç¡®ä¿ç»Ÿè®¡çš„æ˜¯æ€»æ ·æœ¬æ•°ï¼Œä¸æ˜¯æˆåŠŸçš„æ•°é‡
        hash_success_rate = (hash_identical_count / total_samples * 100) if total_samples > 0 else 0
        
        print(f"\nå“ˆå¸Œæ¯”è¾ƒç»“æœ:")
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"  å“ˆå¸Œç›¸åŒ: {hash_identical_count}")
        print(f"  æˆåŠŸç‡: {hash_success_rate:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)")
        
        return {
            'total_samples': total_samples,
            'identical_count': hash_identical_count,
            'success_rate': hash_success_rate,
            'results': hash_comparison_results
        }
    
    def _evaluate_similarity_correct(self, txt_dir, ref_dir, temp_generated_dir, total_samples):
        """
        æ‰§è¡Œå›¾åƒç›¸ä¼¼åº¦è¯„ä¼° (ä¿®æ­£ç‰ˆæœ¬ï¼šåŸºäºæ€»æ ·æœ¬æ•°è®¡ç®—)
        
        Args:
            txt_dir (str): txtæ–‡ä»¶ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•
            temp_generated_dir (str): ä¸´æ—¶ç”Ÿæˆå›¾ç‰‡ç›®å½•
            total_samples (int): æ€»æ ·æœ¬æ•°
            
        Returns:
            dict: ç›¸ä¼¼åº¦è¯„ä¼°ç»“æœ
        """
        # è·å–æ‰€æœ‰txtæ–‡ä»¶åˆ—è¡¨
        txt_files = [f for f in os.listdir(txt_dir) if f.endswith('.txt')]
        txt_files.sort()
        
        similarity_results = []
        similarity_passed_count = 0
        
        for txt_file in txt_files:
            base_name = os.path.splitext(txt_file)[0]
            txt_path = os.path.join(txt_dir, txt_file)
            
            # æŸ¥æ‰¾å¯¹åº”çš„å‚è€ƒå›¾ç‰‡
            ref_image = None
            for ext in ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']:
                potential_ref = os.path.join(ref_dir, base_name + ext)
                if os.path.exists(potential_ref):
                    ref_image = potential_ref
                    break
            
            generated_image = os.path.join(temp_generated_dir, f"{base_name}.png")
            
            result = {
                'base_name': base_name,
                'txt_file': txt_path,
                'ref_image': ref_image,
                'generated_image': generated_image,
                'ref_exists': ref_image is not None,
                'generated_exists': os.path.exists(generated_image),
                'similarity_score': 0.0,
                'similarity_passed': False,
                'similarity_binary_score': 0,  # 0 æˆ– 1
                'error': None
            }
            
            if not result['ref_exists']:
                result['error'] = 'å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨'
                print(f"  âœ— {base_name}: å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨")
            elif not result['generated_exists']:
                result['error'] = 'LaTeXç¼–è¯‘å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡'
                print(f"  âœ— {base_name}: LaTeXç¼–è¯‘å¤±è´¥ï¼Œç›¸ä¼¼åº¦å¾—åˆ†=0")
                # æ³¨æ„ï¼šè¿™é‡Œsimilarity_scoreä¿æŒ0.0ï¼Œsimilarity_binary_scoreä¿æŒ0
            else:
                try:
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    similarity_scores = self.similarity_evaluator.similarity_calculator.comprehensive_similarity(
                        generated_image, ref_image
                    )
                    
                    result['similarity_score'] = similarity_scores['comprehensive']
                    result['detailed_scores'] = similarity_scores
                    
                    # æ ¹æ®é˜ˆå€¼åˆ¤æ–­æ˜¯å¦é€šè¿‡
                    if result['similarity_score'] >= self.similarity_threshold:
                        result['similarity_passed'] = True
                        result['similarity_binary_score'] = 1
                        similarity_passed_count += 1
                        print(f"  âœ“ {base_name}: ç›¸ä¼¼åº¦ {result['similarity_score']:.4f} (â‰¥{self.similarity_threshold})")
                    else:
                        print(f"  âœ— {base_name}: ç›¸ä¼¼åº¦ {result['similarity_score']:.4f} (<{self.similarity_threshold})")
                        
                except Exception as e:
                    result['error'] = f'ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}'
                    print(f"  âœ— {base_name}: ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥")
            
            similarity_results.append(result)
        
        # å…³é”®ä¿®æ­£ï¼šåŸºäºæ€»æ ·æœ¬æ•°è®¡ç®—æˆåŠŸç‡ï¼Œè€Œä¸æ˜¯æˆåŠŸç”Ÿæˆçš„å›¾ç‰‡æ•°
        similarity_success_rate = (similarity_passed_count / total_samples * 100) if total_samples > 0 else 0
        
        print(f"\nç›¸ä¼¼åº¦æ¯”è¾ƒç»“æœ:")
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"  ç›¸ä¼¼åº¦é€šè¿‡: {similarity_passed_count}")
        print(f"  æˆåŠŸç‡: {similarity_success_rate:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)")
        
        return {
            'total_samples': total_samples,
            'passed_count': similarity_passed_count,
            'success_rate': similarity_success_rate,
            'results': similarity_results
        }
    
    def _calculate_comprehensive_score(self, hash_results, similarity_results):
        """
        è®¡ç®—ç»¼åˆå¾—åˆ†
        
        Args:
            hash_results (dict): å“ˆå¸Œæ¯”è¾ƒç»“æœ
            similarity_results (dict): ç›¸ä¼¼åº¦æ¯”è¾ƒç»“æœ
            
        Returns:
            dict: ç»¼åˆè¯„ä¼°ç»“æœ
        """
        # ä¸¤ä¸ªç»“æœåº”è¯¥æœ‰ç›¸åŒçš„æ€»æ ·æœ¬æ•°
        total_samples = hash_results['total_samples']
        assert total_samples == similarity_results['total_samples'], "å“ˆå¸Œå’Œç›¸ä¼¼åº¦è¯„ä¼°çš„æ ·æœ¬æ•°ä¸ä¸€è‡´"
        
        if total_samples == 0:
            return {
                'total_samples': 0,
                'final_score': 0.0,
                'hash_component': 0.0,
                'similarity_component': 0.0,
                'detailed_results': []
            }
        
        # è®¡ç®—åŠ æƒå¾—åˆ†
        hash_component_score = hash_results['success_rate'] * self.hash_weight
        similarity_component_score = similarity_results['success_rate'] * self.similarity_weight
        final_score = hash_component_score + similarity_component_score
        
        # åˆå¹¶è¯¦ç»†ç»“æœ
        detailed_results = []
        hash_dict = {r['base_name']: r for r in hash_results['results']}
        similarity_dict = {r['base_name']: r for r in similarity_results['results']}
        
        all_base_names = set(hash_dict.keys()) | set(similarity_dict.keys())
        
        for base_name in sorted(all_base_names):
            hash_result = hash_dict.get(base_name, {'hash_score': 0, 'hash_identical': False})
            similarity_result = similarity_dict.get(base_name, {'similarity_binary_score': 0, 'similarity_score': 0.0})
            
            # è®¡ç®—è¯¥æ ·æœ¬çš„ç»¼åˆå¾—åˆ†
            sample_hash_score = hash_result['hash_score'] * self.hash_weight
            sample_similarity_score = similarity_result['similarity_binary_score'] * self.similarity_weight
            sample_final_score = sample_hash_score + sample_similarity_score
            
            detailed_results.append({
                'base_name': base_name,
                'hash_score': hash_result['hash_score'],
                'similarity_binary_score': similarity_result['similarity_binary_score'],
                'similarity_raw_score': similarity_result.get('similarity_score', 0.0),
                'weighted_hash_score': sample_hash_score,
                'weighted_similarity_score': sample_similarity_score,
                'final_score': sample_final_score,
                'hash_identical': hash_result.get('hash_identical', False),
                'similarity_passed': similarity_result.get('similarity_passed', False),
                'hash_error': hash_result.get('error'),
                'similarity_error': similarity_result.get('error')
            })
        
        return {
            'total_samples': total_samples,
            'final_score': final_score,
            'hash_component': hash_component_score,
            'similarity_component': similarity_component_score,
            'hash_success_rate': hash_results['success_rate'],
            'similarity_success_rate': similarity_results['success_rate'],
            'detailed_results': detailed_results,
            'weights': {
                'hash_weight': self.hash_weight,
                'similarity_weight': self.similarity_weight
            }
        }
    
    def _print_final_results(self, comprehensive_results):
        """
        æ‰“å°æœ€ç»ˆç»“æœ
        
        Args:
            comprehensive_results (dict): ç»¼åˆè¯„ä¼°ç»“æœ
        """
        print(f"\n{'='*80}")
        print("æœ€ç»ˆç»¼åˆè¯„ä¼°ç»“æœ")
        print(f"{'='*80}")
        
        print(f"æ€»æ ·æœ¬æ•°: {comprehensive_results['total_samples']}")
        print(f"å“ˆå¸Œæ¯”è¾ƒæˆåŠŸç‡: {comprehensive_results['hash_success_rate']:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)")
        print(f"ç›¸ä¼¼åº¦æ¯”è¾ƒæˆåŠŸç‡: {comprehensive_results['similarity_success_rate']:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)")
        print(f"")
        print(f"åŠ æƒå¾—åˆ†ç»„æˆ:")
        print(f"  å“ˆå¸Œç»„ä»¶å¾—åˆ†: {comprehensive_results['hash_component']:.2f} (æƒé‡: {comprehensive_results['weights']['hash_weight']})")
        print(f"  ç›¸ä¼¼åº¦ç»„ä»¶å¾—åˆ†: {comprehensive_results['similarity_component']:.2f} (æƒé‡: {comprehensive_results['weights']['similarity_weight']})")
        print(f"")
        print(f"ğŸ¯ æœ€ç»ˆç»¼åˆå¾—åˆ†: {comprehensive_results['final_score']:.2f}")
        
        # ç»Ÿè®¡å„ç§æƒ…å†µçš„æ ·æœ¬æ•°
        both_passed = sum(1 for r in comprehensive_results['detailed_results'] 
                         if r['hash_identical'] and r['similarity_passed'])
        only_hash_passed = sum(1 for r in comprehensive_results['detailed_results'] 
                              if r['hash_identical'] and not r['similarity_passed'])
        only_similarity_passed = sum(1 for r in comprehensive_results['detailed_results'] 
                                    if not r['hash_identical'] and r['similarity_passed'])
        both_failed = sum(1 for r in comprehensive_results['detailed_results'] 
                         if not r['hash_identical'] and not r['similarity_passed'])
        
        print(f"\næ ·æœ¬åˆ†å¸ƒ:")
        print(f"  ä¸¤é¡¹éƒ½é€šè¿‡: {both_passed}")
        print(f"  ä»…å“ˆå¸Œé€šè¿‡: {only_hash_passed}")
        print(f"  ä»…ç›¸ä¼¼åº¦é€šè¿‡: {only_similarity_passed}")
        print(f"  ä¸¤é¡¹éƒ½å¤±è´¥: {both_failed}")
        
        # ç»Ÿè®¡å¤±è´¥åŸå› 
        latex_compile_failed = sum(1 for r in comprehensive_results['detailed_results'] 
                                  if r.get('hash_error') == 'LaTeXç¼–è¯‘å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡' or 
                                     r.get('similarity_error') == 'LaTeXç¼–è¯‘å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡')
        
        print(f"\nå¤±è´¥åŸå› ç»Ÿè®¡:")
        print(f"  LaTeXç¼–è¯‘å¤±è´¥: {latex_compile_failed}")
        print(f"  å…¶ä»–åŸå› å¤±è´¥: {both_failed - latex_compile_failed}")
    
    def _generate_comprehensive_report(self, comprehensive_results, report_path):
        """
        ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š
        
        Args:
            comprehensive_results (dict): ç»¼åˆè¯„ä¼°ç»“æœ
            report_path (str): æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            os.makedirs(os.path.dirname(report_path), exist_ok=True)
            
            from datetime import datetime
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            report_content = f"""LaTeXå›¾ç‰‡ç»¼åˆç›¸ä¼¼åº¦è¯„ä¼°æŠ¥å‘Š
{'='*80}
è¯„ä¼°æ—¶é—´: {current_time}
è¯„ä¼°æ–¹æ³•: å“ˆå¸Œæ¯”è¾ƒ + å›¾åƒç›¸ä¼¼åº¦ (åŠ æƒ)

æƒé‡é…ç½®:
{'='*40}
å“ˆå¸Œæ¯”è¾ƒæƒé‡: {comprehensive_results['weights']['hash_weight']}
ç›¸ä¼¼åº¦è®¡ç®—æƒé‡: {comprehensive_results['weights']['similarity_weight']}
ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}

æ€»ä½“ç»Ÿè®¡:
{'='*40}
æ€»æ ·æœ¬æ•°: {comprehensive_results['total_samples']}
å“ˆå¸Œæ¯”è¾ƒæˆåŠŸç‡: {comprehensive_results['hash_success_rate']:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)
ç›¸ä¼¼åº¦æ¯”è¾ƒæˆåŠŸç‡: {comprehensive_results['similarity_success_rate']:.2f}% (åŸºäºæ€»æ ·æœ¬æ•°)

åŠ æƒå¾—åˆ†:
{'='*40}
å“ˆå¸Œç»„ä»¶å¾—åˆ†: {comprehensive_results['hash_component']:.2f}
ç›¸ä¼¼åº¦ç»„ä»¶å¾—åˆ†: {comprehensive_results['similarity_component']:.2f}
æœ€ç»ˆç»¼åˆå¾—åˆ†: {comprehensive_results['final_score']:.2f}

è¯¦ç»†ç»“æœ:
{'='*80}
"""
            
            # æŒ‰æœ€ç»ˆå¾—åˆ†æ’åº
            sorted_results = sorted(comprehensive_results['detailed_results'], 
                                  key=lambda x: x['final_score'], reverse=True)
            
            for i, result in enumerate(sorted_results, 1):
                status_hash = "âœ“" if result['hash_identical'] else "âœ—"
                status_sim = "âœ“" if result['similarity_passed'] else "âœ—"
                
                report_content += f"{i:3d}. {result['base_name']}\n"
                report_content += f"     å“ˆå¸Œæ¯”è¾ƒ: {status_hash} ({result['hash_score']})\n"
                report_content += f"     ç›¸ä¼¼åº¦: {status_sim} ({result['similarity_raw_score']:.4f})\n"
                report_content += f"     åŠ æƒå¾—åˆ†: å“ˆå¸Œ={result['weighted_hash_score']:.2f} + ç›¸ä¼¼åº¦={result['weighted_similarity_score']:.2f} = {result['final_score']:.2f}\n"
                
                # æ·»åŠ é”™è¯¯ä¿¡æ¯
                if result.get('hash_error'):
                    report_content += f"     å“ˆå¸Œé”™è¯¯: {result['hash_error']}\n"
                if result.get('similarity_error'):
                    report_content += f"     ç›¸ä¼¼åº¦é”™è¯¯: {result['similarity_error']}\n"
                
                report_content += "\n"
            
            # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nğŸ“Š ç»¼åˆè¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
        except Exception as e:
            print(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    txt_dir = "./data/samples_test2"
    ref_dir = "./data/output_eval"
    report_path = "./comprehensive_evaluation_report.txt"
    
    # é…ç½®æƒé‡
    hash_weight = 0.5
    similarity_weight = 0.5
    similarity_threshold = 0.99  # ç›¸ä¼¼åº¦é˜ˆå€¼
    
    print("LaTeXå›¾ç‰‡ç»¼åˆç›¸ä¼¼åº¦è¯„ä¼°")
    print("=" * 80)
    print(f"é…ç½®ä¿¡æ¯:")
    print(f"  txtæ–‡ä»¶ç›®å½•: {txt_dir}")
    print(f"  å‚è€ƒå›¾ç‰‡ç›®å½•: {ref_dir}")
    print(f"  æŠ¥å‘Šè¾“å‡ºè·¯å¾„: {report_path}")
    print(f"  å“ˆå¸Œæ¯”è¾ƒæƒé‡: {hash_weight}")
    print(f"  ç›¸ä¼¼åº¦è®¡ç®—æƒé‡: {similarity_weight}")
    print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}")
    print(f"  âš ï¸  æ³¨æ„: æ— æ³•ç”Ÿæˆå›¾ç‰‡çš„æ ·æœ¬è®¡ä¸º0åˆ†ï¼Œåˆ†æ¯ä»ä¸ºæ€»æ ·æœ¬æ•°")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(txt_dir):
        print(f"\nâŒ é”™è¯¯: txtç›®å½•ä¸å­˜åœ¨ - {txt_dir}")
        return
    
    if not os.path.exists(ref_dir):
        print(f"\nâŒ é”™è¯¯: å‚è€ƒç›®å½•ä¸å­˜åœ¨ - {ref_dir}")
        return
    
    try:
        # åˆ›å»ºç»¼åˆè¯„ä¼°å™¨
        evaluator = ComprehensiveEvaluator(
            hash_weight=hash_weight,
            similarity_weight=similarity_weight,
            similarity_threshold=similarity_threshold
        )
        
        # æ‰§è¡Œç»¼åˆè¯„ä¼°
        results = evaluator.evaluate_comprehensive(
            txt_dir=txt_dir,
            ref_dir=ref_dir,
            output_report=report_path,
            keep_temp_images=False  # è®¾ä¸ºTrueå¯ä¿ç•™ç”Ÿæˆçš„ä¸´æ—¶å›¾ç‰‡
        )
        
        print(f"\nğŸ‰ è¯„ä¼°å®Œæˆï¼æœ€ç»ˆå¾—åˆ†: {results['final_score']:.2f}")
        
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()