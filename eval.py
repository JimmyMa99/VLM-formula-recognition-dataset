#!/usr/bin/env python3
"""
ä¸€é”®æµ‹è¯„è„šæœ¬
åˆå¹¶æ¨¡å‹æ¨ç†å’Œæ€§èƒ½è¯„ä¼°ä¸¤ä¸ªæ­¥éª¤ï¼Œå®ç°å®Œæ•´çš„å…¬å¼è¯†åˆ«æµ‹è¯„æµç¨‹
"""

import os
import sys
import argparse
import shutil
from pathlib import Path

# æ·»åŠ è·¯å¾„å¯¼å…¥
sys.path.append("./infer_core")
sys.path.append("./eval_core")
from infer_core.inferVLM import MathFormulaOCR
from infer_core.interns1 import MathFormulaOCRInternS1
from main_eval import ComprehensiveEvaluator


class EvaluatorPipeline:
    """è¯„ä¼°ç®¡é“ï¼Œå°è£…å®Œæ•´çš„æ¨ç†å’Œè¯„ä¼°æµç¨‹"""

    def __init__(
        self,
        model_path,
        hash_weight=0.5,
        similarity_weight=0.5,
        similarity_threshold=0.6,
    ):
        """
        åˆå§‹åŒ–è¯„ä¼°ç®¡é“

        Args:
            model_path (str): æ¨¡å‹è·¯å¾„
            hash_weight (float): å“ˆå¸Œæ¯”è¾ƒæƒé‡
            similarity_weight (float): ç›¸ä¼¼åº¦è®¡ç®—æƒé‡
            similarity_threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.model_path = model_path
        self.hash_weight = hash_weight
        self.similarity_weight = similarity_weight
        self.similarity_threshold = similarity_threshold

        # åˆå§‹åŒ–ç»„ä»¶
        self.ocr = None
        self.evaluator = None

        print("=" * 80)
        print("ğŸš€ åˆå§‹åŒ–æµ‹è¯„ç®¡é“")
        print("=" * 80)
        print(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
        print(f"å“ˆå¸Œæƒé‡: {self.hash_weight}")
        print(f"ç›¸ä¼¼åº¦æƒé‡: {self.similarity_weight}")
        print(f"ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}")
        print("=" * 80)

    def _init_ocr(self):
        """åˆå§‹åŒ–OCRç»„ä»¶"""
        if self.ocr is None:
            print("ğŸ“¥ æ­£åœ¨åˆå§‹åŒ–OCRç»„ä»¶...")
            # æ ¹æ®æ¨¡å‹è·¯å¾„åˆ¤æ–­ä½¿ç”¨å“ªä¸ªOCRç±»
            if "internvl3" or "InternVL3" in self.model_path.lower():
                self.ocr = MathFormulaOCR(
                    model_path=self.model_path, load_in_8bit=False
                )
                print("âœ… ä½¿ç”¨InternVL3æ¨¡å‹ocrç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            else:
                self.ocr = MathFormulaOCRInternS1(
                    model_path=self.model_path, load_in_8bit=False
                )
                print("âœ… ä½¿ç”¨InternS1æ¨¡å‹ocrç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def _init_evaluator(self):
        """åˆå§‹åŒ–è¯„ä¼°å™¨ç»„ä»¶"""
        if self.evaluator is None:
            print("ğŸ“Š æ­£åœ¨åˆå§‹åŒ–è¯„ä¼°å™¨ç»„ä»¶...")
            self.evaluator = ComprehensiveEvaluator(
                hash_weight=self.hash_weight,
                similarity_weight=self.similarity_weight,
                similarity_threshold=self.similarity_threshold,
            )
            print("âœ… è¯„ä¼°å™¨ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    def run_inference(self, input_directory, output_directory):
        """
        æ‰§è¡Œæ¨¡å‹æ¨ç†

        Args:
            input_directory (str): è¾“å…¥å›¾ç‰‡ç›®å½•
            output_directory (str): è¾“å‡ºLaTeXæ–‡æœ¬ç›®å½•
        """
        print("\nğŸ” æ­¥éª¤1: æ¨¡å‹æ¨ç†")
        print("-" * 60)

        self._init_ocr()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_directory, exist_ok=True)

        # æ‰¹é‡å¤„ç†å›¾ç‰‡
        self.ocr.process_images_batch(input_directory, output_directory)

        print(f"âœ… æ¨ç†å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_directory}")

    def run_evaluation(self, txt_dir, ref_dir, output_report, keep_temp_images=False):
        """
        æ‰§è¡Œæ€§èƒ½è¯„ä¼°

        Args:
            txt_dir (str): LaTeXæ–‡æœ¬ç›®å½•
            ref_dir (str): å‚è€ƒå›¾ç‰‡ç›®å½•
            output_report (str): è¾“å‡ºæŠ¥å‘Šè·¯å¾„
            keep_temp_images (bool): æ˜¯å¦ä¿ç•™ä¸´æ—¶å›¾ç‰‡

        Returns:
            dict: è¯„ä¼°ç»“æœ
        """
        print("\nğŸ“ˆ æ­¥éª¤2: æ€§èƒ½è¯„ä¼°")
        print("-" * 60)

        self._init_evaluator()

        # æ‰§è¡Œç»¼åˆè¯„ä¼°
        results = self.evaluator.evaluate_comprehensive(
            txt_dir=txt_dir,
            ref_dir=ref_dir,
            output_report=output_report,
            keep_temp_images=keep_temp_images,
        )

        print(f"âœ… è¯„ä¼°å®Œæˆï¼ŒæŠ¥å‘Šç”Ÿæˆ: {output_report}")
        return results

    def run_complete_pipeline(
        self, input_directory, output_directory, report_path, keep_temp_images=False
    ):
        """
        è¿è¡Œå®Œæ•´çš„æµ‹è¯„æµç¨‹

        Args:
            input_directory (str): è¾“å…¥å›¾ç‰‡ç›®å½•ï¼ˆåŒæ—¶ä½œä¸ºå‚è€ƒç›®å½•ï¼‰
            output_directory (str): ä¸­é—´ç»“æœLaTeXæ–‡æœ¬ç›®å½•
            report_path (str): æœ€ç»ˆæŠ¥å‘Šè·¯å¾„
            keep_temp_images (bool): æ˜¯å¦ä¿ç•™ä¸´æ—¶å›¾ç‰‡

        Returns:
            dict: æœ€ç»ˆè¯„ä¼°ç»“æœ
        """
        print("ğŸ¯ å¼€å§‹å®Œæ•´æµ‹è¯„æµç¨‹")

        try:
            # æ­¥éª¤1: æ¨¡å‹æ¨ç†
            self.run_inference(input_directory, output_directory)

            # æ­¥éª¤2: æ€§èƒ½è¯„ä¼°ï¼ˆä½¿ç”¨è¾“å…¥ç›®å½•ä½œä¸ºå‚è€ƒç›®å½•ï¼‰
            print(f"ğŸ“ ä½¿ç”¨è¾“å…¥ç›®å½•ä½œä¸ºå‚è€ƒç›®å½•è¿›è¡Œè¯„ä¼°: {input_directory}")
            results = self.run_evaluation(
                output_directory, input_directory, report_path, keep_temp_images
            )

            print("\nğŸ‰ æµ‹è¯„æµç¨‹å…¨éƒ¨å®Œæˆ!")
            print(f"ğŸ“Š æœ€ç»ˆå¾—åˆ†: {results['final_score']:.2f}")

            return results

        except Exception as e:
            print(f"\nâŒ æµ‹è¯„æµç¨‹å¤±è´¥: {e}")
            raise


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ä¸€é”®å…¬å¼è¯†åˆ«æµ‹è¯„è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python eval.py \\
      --model-path /path/to/model \\
      --input-dir /path/to/images \\
      --output-dir ./results \\
      --report-path ./evaluation_report.txt \\
      --ref-dir ./data/output_eval

  python eval.py \\
      --model-path OpenGVLab/InternVL3-1B \\
      --input-dir ./data/samples_test \\
      --output-dir ./inference_results \\
      --report-path ./report.txt \\
      --ref-dir ./data/output_eval \\
      --hash-weight 0.6 \\
      --similarity-weight 0.4
        """,
    )

    # å¿…éœ€å‚æ•°
    parser.add_argument("--model-path", required=True, help="æ¨¡å‹è·¯å¾„ (å¿…éœ€)")

    parser.add_argument("--input-dir", required=True, help="è¾“å…¥å›¾ç‰‡ç›®å½• (å¿…éœ€)")

    parser.add_argument(
        "--output-dir", required=True, help="ä¸­é—´ç»“æœLaTeXæ–‡æœ¬è¾“å‡ºç›®å½• (å¿…éœ€)"
    )

    parser.add_argument("--report-path", required=True, help="æœ€ç»ˆè¯„ä¼°æŠ¥å‘Šè·¯å¾„ (å¿…éœ€)")

    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--hash-weight", type=float, default=0.5, help="å“ˆå¸Œæ¯”è¾ƒæƒé‡ (é»˜è®¤: 0.5)"
    )

    parser.add_argument(
        "--similarity-weight",
        type=float,
        default=0.5,
        help="ç›¸ä¼¼åº¦è®¡ç®—æƒé‡ (é»˜è®¤: 0.5)",
    )

    parser.add_argument(
        "--similarity-threshold",
        type=float,
        default=0.99,
        help="ç›¸ä¼¼åº¦é˜ˆå€¼ (é»˜è®¤: 0.6)",
    )

    parser.add_argument(
        "--keep-temp-images", action="store_true", help="ä¿ç•™ä¸´æ—¶ç”Ÿæˆçš„å›¾ç‰‡"
    )

    return parser.parse_args()


def validate_paths(args):
    """éªŒè¯è·¯å¾„å‚æ•°"""
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_dir):
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(args.output_dir), exist_ok=True)
    os.makedirs(os.path.dirname(args.report_path), exist_ok=True)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‚æ•°
        args = parse_arguments()

        print("ğŸ”§ é…ç½®ä¿¡æ¯:")
        print(f"  æ¨¡å‹è·¯å¾„: {args.model_path}")
        print(f"  è¾“å…¥ç›®å½•: {args.input_dir}")
        print(f"  ä¸­é—´è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"  æŠ¥å‘Šè·¯å¾„: {args.report_path}")
        print(f"  å“ˆå¸Œæƒé‡: {args.hash_weight}")
        print(f"  ç›¸ä¼¼åº¦æƒé‡: {args.similarity_weight}")
        print(f"  ç›¸ä¼¼åº¦é˜ˆå€¼: {args.similarity_threshold}")
        print(f"  ä¿ç•™ä¸´æ—¶å›¾ç‰‡: {args.keep_temp_images}")

        # éªŒè¯è·¯å¾„
        validate_paths(args)

        # åˆ›å»ºè¯„ä¼°ç®¡é“
        pipeline = EvaluatorPipeline(
            model_path=args.model_path,
            hash_weight=args.hash_weight,
            similarity_weight=args.similarity_weight,
            similarity_threshold=args.similarity_threshold,
        )

        # è¿è¡Œå®Œæ•´æµç¨‹
        results = pipeline.run_complete_pipeline(
            input_directory=args.input_dir,
            output_directory=args.output_dir,
            report_path=args.report_path,
            keep_temp_images=args.keep_temp_images,
        )

        print(f"\nğŸ‰ æµ‹è¯„å®Œæˆ! æœ€ç»ˆå¾—åˆ†: {results['final_score']:.2f}")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
